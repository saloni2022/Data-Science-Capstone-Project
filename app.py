# -*- coding: utf-8 -*-
"""EDA for car details.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hhwth3wrr0CH1rnvToD8NhCDMny-leXd
"""

import pandas as pd
import numpy as num
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv(r'/content/CAR DETAILS.csv')
df

df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

df.head()

df.info()

df.describe()

df.isna()

df.shape

df.columns

# Split the column name to get the model of the car
df["model"] = df.name.apply(lambda x : ' '.join(x.split(' ')[:1]))
df['model'].value_counts()

# Check null values in dataset
df.isnull().sum()

df.dropna()

# Check duplicated row in dataset
df[df.duplicated()]

# Drop all duplicated row
df = df.drop_duplicates()

df.shape

# View unique values from categorical features
categorical = [col for col in df.columns if df[col].dtypes == 'O']

for col in categorical:
  print(df[col].unique())

"""EDA"""

car = df.copy()

#Model Distribution
car["model"].value_counts().index

def percent(ax):
    heightlst = []
    for i in ax.patches:
        heightlst.append(i.get_height())
    total = sum(heightlst)

    for i in ax.patches:
        x = i.get_x()+0.2
        height = i.get_height()+4.3
        value = ("{0:.2f}".format((i.get_height()/total)*100)+'%')

        ax.text(x, height, value, fontsize=14,color='black')

# Plot of Car Models Distribution
figure = plt.figure(figsize=(12,8))
plt.title('Car Models Distribution', fontsize=18)
plot = sns.countplot(x="model", data=car, order = car['model'].value_counts().index[:5], palette='Blues_r')
percent(plot)

plt.show()

def categorical_summarized(dataframe, x=None, y=None, hue=None, palette='Blues_r', verbose=True):
    '''
    Helper function that gives a quick summary of a given column of categorical data
    Arguments
    =========
    dataframe: pandas dataframe
    x: str. horizontal axis to plot the labels of categorical data, y would be the count
    y: str. vertical axis to plot the labels of categorical data, x would be the count
    hue: str. if you want to compare it another variable (usually the target variable)
    palette: array-like. Colour of the plot
    Returns
    =======
    Quick Stats of the data and also the count plot
    '''
    if x == None:
        column_interested = y
    else:
        column_interested = x
    series = dataframe[column_interested]
    print(series.describe())
    print('mode: ', series.mode())
    if verbose:
        print('='*80)
        print(series.value_counts())

    sns.countplot(x=x, y=y, hue=hue, data=dataframe, palette=palette)
    plt.show()

categorical_summarized(car, x='fuel')

categorical_summarized(car, x='fuel')

categorical_summarized(car, x='transmission')

categorical_summarized(car, x='owner')

# Subplot of Categorical Summary
plt.figure(figsize=(18,8))

plt.subplot(2,2,1)
plt.title('Fuel Summary', fontsize=18)
sns.countplot(data=car, x='fuel', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,2)
plt.title('Transmission Summary', fontsize=18)
sns.countplot(data=car, x='transmission', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,3)
plt.title('Owner Summary', fontsize=18)
sns.countplot(data=car, x='owner', palette='Blues_r')
plt.xlabel('')
plt.subplot(2,2,4)
plt.title('Seller Type Summary', fontsize=18)
sns.countplot(data=car, x='seller_type', palette='Blues_r')
plt.xlabel('')

plt.tight_layout()
plt.show()

#Correlation Matrix
plt.figure(figsize=(10,10))
plt.title('Correlation Matrix', fontsize=18)
sns.heatmap(car.corr(), cbar=True, annot=True, cmap='Blues')

#Correlation Between selling_price and km_driven
plt.figure(figsize=(18,8))
plt.title('km_driven by selling_price Distribution', fontsize=18)
sns.scatterplot(data=car, x='km_driven', y='selling_price')

plt.ticklabel_format(style='plain', axis='y')

#Correlation Between selling_price and year
plt.figure(figsize=(18,8))
plt.title('year by selling_price Distribution', fontsize=18)
sns.scatterplot(data=car, x='year', y='selling_price')

plt.ticklabel_format(style='plain', axis='y')

#How does year affects km_driven?
plt.figure(figsize=(12,10))
plt.title('year by km_driven Distribution', fontsize=18)
sns.histplot(data=car, x='year', y='km_driven', bins=100)
#plt.ticklabel_format(style='plain', axis='x')

#Detailed Analysis in selling_price, km_driven, yearÂ¶
pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='selling_price', ascending=False)

pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='km_driven', ascending=False)

pd.pivot_table(data=car, index=['name'], values=['selling_price','km_driven','year']).sort_values(by='year', ascending=False)

#How does Categorical Feature affects selling_price
plt.figure(figsize=(24,16))

plt.subplot(2,2,1)
plt.title('Fuel by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='fuel', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,2)
plt.title('Transmission by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='transmission', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,3)
plt.title('Owner by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='owner', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')
plt.subplot(2,2,4)
plt.title('Seller_type by selling_price Distribution', fontsize=18)
sns.boxplot(data=car, x='selling_price', y='seller_type', palette='Set2')
plt.ticklabel_format(style='plain', axis='x')

"""Multivariate EDA"""

sns.pairplot(data=df)
plt.show()

plt.figure(figsize=(10,10))
sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True)
plt.show()

"""Independent and Dependent Variables"""

df.columns

data={
      'year' :[2007, 20012, 2017],
      'km_driven' :[70000,100000, 46000],
      'selling_price' :[60000, 600000, 250000 ]
      }
df = pd.DataFrame(data)

"""Splitting data"""

X = df.drop('year', axis=1)#Features (all columns except 'year')

y = df['year']

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2 , random_state=20)

"""Applying Model"""

from sklearn.linear_model import LinearRegression

model= LinearRegression()

model.fit(X_train,y_train)

y_pred = model.predict(X_test)

!pip install -U scikit-learn

from sklearn.preprocessing import StandardScaler

scaler= StandardScaler()
X_scaled = scaler.fit_transform(X)

from sklearn.preprocessing import MinMaxScaler
scaler =MinMaxScaler()
X_normalized = scaler.fit_transform(X)

import seaborn as sns
import matplotlib.pyplot

sns.pairplot(df)
#Exploring data distribution and relationships
plt.show()

df.to_csv('cleaned_data.csv',index=False)

from sklearn.metrics import mean_squared_error,r2_score

"""Evaluate the model"""

mse= mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

r2= r2_score(y_test,y_pred)
print(f'R-squared: {r2}')

"""#Plotting the predictions against the actual values

"""

plt.scatter(X_test['km_driven'], y_test, color=(0.2,0.4,0.6), label='Actual')
plt.scatter(X_test['km_driven'], y_pred, color=(1, 0, 0, 1), label='Predicted')
plt.xlabel('km_driven')
plt.ylabel('year')
plt.legend()
plt.show()

"""Model Summary"""

!pip install numpy statsmodels scikit-learn

import statsmodels.api as sm
X= sm.add_constant(X_train)
model = sm.OLS(y_train,X).fit()
print(model.summary())

from sklearn.metrics import mean_absolute_error
import numpy as np

y.test = np.array([y_test])
y.pred = np.array([y_pred])

mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) *100
print(f'MAPE: {mape: .2f}%')

import pandas as pd
import seaborn as sns

# Assuming 'df' is your DataFrame
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True)

from sklearn.linear_model import Lasso

# Assuming X_train and y_train are your training data
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
importances = np.abs(lasso.coef_)

df=pd.read_csv(r'/content/cleaned_data.csv')

from sklearn.metrics import mean_absolute_error
import numpy as np

y.test = np.array([y_test])
y.pred = np.array([y_pred])

mape = np.mean(np.abs((y_test - y_pred) / (y_test + 1e-8))) *100
print(f'MAPE: {mape: .2f}%')

"""20 data points from the CAR DETAILS"""

df_1 = pd.read_csv(r'/content/Car_details1.csv')
df_1

df_1.dropna(inplace=True)
df_1.drop_duplicates(inplace=True)

df_1.head()

df_1.info()

df_1.describe()

df_1.isna()

df_1.shape

df_1.columns

# Split the column name to get the model of the car
df_1["model"] = df_1.name.apply(lambda x : ' '.join(x.split(' ')[:1]))
df_1['model'].value_counts()

# Check null values in dataset
df_1.isnull().sum()

df_1.dropna()

# Check duplicated row in dataset
df_1[df_1.duplicated()]

# Drop all duplicated row
df_1 = df_1.drop_duplicates()

df_1.shape

# View unique values from categorical features
categorical_1 = [col for col in df_1.columns if df_1[col].dtypes == 'O']

for col in categorical_1:
  print(df_1[col].unique())

df_1.columns

data_1={
      'year' :[2007, 20012, 2017],
      'km_driven' :[70000,100000, 46000],
      'selling_price' :[60000, 600000, 250000 ]
      }
df_1 = pd.DataFrame(data_1)

X_1 = df_1.drop('year', axis=1)#Features (all columns except 'year')

y_1 = df_1['year']

from sklearn.model_selection import train_test_split
X_1_train,X_1_test,y_1_train,y_1_test=train_test_split(X_1,y_1,test_size=0.2 , random_state=20)

from sklearn.linear_model import LinearRegression

model_1= LinearRegression()

model_1.fit(X_1_train,y_1_train)

y_1_pred = model_1.predict(X_1_test)

from sklearn.preprocessing import StandardScaler

scaler_1= StandardScaler()
X_1_scaled = scaler.fit_transform(X_1)

from sklearn.preprocessing import MinMaxScaler
scaler_1 =MinMaxScaler()
X_1_normalized = scaler.fit_transform(X_1)

import seaborn as sns
import matplotlib.pyplot

sns.pairplot(df_1)
#Exploring data distribution and relationships
plt.show()

df_1.to_csv('cleaned_data.csv',index=False)

from sklearn.metrics import mean_squared_error,r2_score

#Evaluate the model
mse_1 = mean_squared_error(y_1_test, y_1_pred)
print(f'Mean Squared Error: {mse_1}')

y_1.test1 = np.array([y_1_test])
y_1.pred1 = np.array([y_1_pred])

mape_1  = np.mean(np.abs((y_1_test - y_1_pred) / (y_1_test + 1e-8))) *100
print(f'MAPE: {mape_1: .2f}%')

import pandas as pd
import seaborn as sns

# Assuming 'df' is your DataFrame
correlation_matrix = df_1.corr()
sns.heatmap(correlation_matrix, annot=True)

